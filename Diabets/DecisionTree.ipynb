{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/chiarorosa/ia_aprendizado_maquina_basico/main/ml-dataset/kaggle-basico/diabetes.csv'\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score # Avaliação de Acurácia\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)\n",
    "df.head()\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do DataFrame após a remoção dos outliers: 992\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dados de exemplo\n",
    "df = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Criar DataFrame\n",
    "df = pd.DataFrame(df, columns=['Value'])\n",
    "\n",
    "# Calcular quartis\n",
    "q1 = df['Value'].quantile(0.25)\n",
    "q3 = df['Value'].quantile(0.75)\n",
    "\n",
    "# Calcular IQR\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Definir limites para outliers\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Remover outliers\n",
    "df_clean = df[~((df < lower_bound) | (df > upper_bound)).any(axis=1)]\n",
    "\n",
    "# Verificar o tamanho do DataFrame após a remoção dos outliers\n",
    "print(\"Tamanho do DataFrame após a remoção dos outliers:\", df_clean.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Dividir em dois conjuntos, treinamento e teste, usando pareto 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_scaled,\n",
    "    y,\n",
    "    test_size=0.2, # pareto\n",
    "    random_state=42 # reproduzivel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Dividir em dois conjuntos, treinamento e teste, usando pareto 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_scaled,\n",
    "    y,\n",
    "    test_size=0.2, # pareto\n",
    "    random_state=42 # reproduzivel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 76.62\n",
      "Melhor modelo: DecisionTreeClassifier(max_depth=20)\n",
      "Parâmetros do melhor modelo: {'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Acurácia anterior: 76.62\n",
      "Acurácia atualizada: 76.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.73288018        nan 0.69220312 0.69708117 0.69214981        nan\n",
      "        nan        nan 0.69529522 0.68901773 0.70363854 0.72468346\n",
      " 0.6547381  0.6709183  0.72477676 0.66456084 0.70371851 0.69544182\n",
      " 0.72629615 0.69218979]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grade = {\n",
    "    'criterion': ['gini', 'entropy'],  # Measure of split quality\n",
    "    'splitter': ['best', 'random'],    # Strategy for choosing splits\n",
    "    'max_depth':[None, 10, 20, 30, 40, 50],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],    # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],       # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],  # Number of features to consider for best split\n",
    "}\n",
    "\n",
    "Tree = RandomizedSearchCV(\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    grade,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_iter=20,  # Número de iterações de busca aleatória\n",
    "    n_jobs=-1,  # Use todos os núcleos disponíveis\n",
    "    random_state=42  # Para reprodutibilidade\n",
    ")\n",
    "\n",
    "Tree.fit(X_train, y_train)\n",
    "\n",
    "melhor = Tree.best_estimator_\n",
    "\n",
    "y_pred = melhor.predict(X_test)\n",
    "\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia: {acuracia * 100:.2f}')\n",
    "print(f'Melhor modelo: {melhor}')\n",
    "print(f'Parâmetros do melhor modelo: {Tree.best_params_}')\n",
    "\n",
    "guardaAcc = 0\n",
    "\n",
    "with open('Melhor Acurracia Tree.txt', 'r+', encoding='utf-8') as f:\n",
    "        try:\n",
    "            linha = f.readline().strip()\n",
    "            if linha.startswith('Acurácia:'):\n",
    "                guardaAcc = float(linha.split(': ')[1]) / 100\n",
    "                print(f'Acurácia anterior: {guardaAcc * 100:.2f}')\n",
    "                if acuracia > guardaAcc:\n",
    "                    f.seek(0) # vai pro inicio\n",
    "                    f.write(f'Acurácia: {acuracia * 100:.2f} \\n')\n",
    "                    \n",
    "                    f.truncate() #  remove residuos antigos\n",
    "                    print(f'Acurácia atualizada: {acuracia * 100:.2f}')\n",
    "                else:\n",
    "                    print('Acurácia não atualizada')\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler o arquivo: {e}\")\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
